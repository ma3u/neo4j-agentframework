# Issue #4: Azure AI Foundry Integration - Investigation & Concept

**Issue**: https://github.com/ma3u/neo4j-agentframework/issues/4
**Date**: 2025-10-18
**Status**: Investigation Complete, Concept Proposed

---

## ğŸ” Problem Statement

**Current State** (from screenshot):
- Azure AI Foundry Assistant configured: `asst_LHQBXYvRhnbFo7KQ7IRbVXRR`
- Model: `gpt-4o-mini` (Deployment: 2025-08-07)
- Custom functions registered: `search_knowledge_base`, `add_document`, `get_statistics`
- **Issue**: Query "What is Neo4j?" returns "I couldn't find this in the knowledge base"

**Expected State**:
- Assistant should call `search_knowledge_base` function
- Function should query Aura instance (`6b870b04`) with 30,006 chunks
- Return relevant content from 12 books
- Generate answer based on retrieved context

**Root Cause**: Functions are registered in Azure AI Foundry but **not connected** to actual RAG service endpoint.

---

## ğŸ“Š Two Implementation Options (Comparison)

### Option 1: Neo4j MCP Servers (Recommended - 70%)

**What It Is**: Use Neo4j's official Model Context Protocol servers

**Available MCP Servers** (from neo4j-contrib/mcp-neo4j):

1. **mcp-neo4j-cypher**
   - Schema extraction
   - Natural language â†’ Cypher query generation
   - Read/write query execution
   - **Use for**: Database queries, schema exploration

2. **mcp-neo4j-memory**
   - Knowledge graph as external memory
   - Entity/relationship tracking
   - Session persistence
   - **Use for**: Conversation context, long-term memory

3. **mcp-neo4j-cloud-aura-api**
   - Aura instance management
   - Create/destroy/scale instances
   - Feature toggles
   - **Use for**: Instance lifecycle management

4. **mcp-neo4j-data-modeling**
   - Graph data model creation
   - Node/relationship definitions
   - Schema visualization
   - **Use for**: Schema design, modeling

**Pros**:
- âœ… **Official Neo4j support** - Maintained by Neo4j team
- âœ… **Production-ready** - Battle-tested, actively maintained
- âœ… **Multi-client support** - Works with Claude Desktop, VS Code, Cursor
- âœ… **Containerized** - Ready for Azure Container Apps deployment
- âœ… **HTTP/SSE transport** - Cloud-native, scalable
- âœ… **Auto-scaling support** - Built for production workloads
- âœ… **Standard protocol** - MCP is becoming industry standard

**Cons**:
- âŒ **No native RAG operations** - We'd need custom MCP server for vector search
- âŒ **Separate deployment** - Additional Container App to manage
- âŒ **Learning curve** - MCP protocol specifics
- âŒ **Extra infrastructure** - ~$50/month for MCP server Container App

**Architecture**:
```
Azure AI Foundry â†’ MCP Protocol â†’ MCP Server (Container App) â†’ Neo4j Aura
                                      â†“
                                  4 Neo4j Servers:
                                  - Cypher
                                  - Memory
                                  - Aura API
                                  - Data Modeling
                                  + Custom RAG Server (we build)
```

**Estimated Effort**: 2-3 weeks
- Week 1: Deploy neo4j-contrib MCP servers
- Week 2: Build custom RAG MCP server
- Week 3: Integrate with Azure AI Foundry

---

### Option 2: Azure AI Foundry Agent Framework (Current - 20%)

**What It Is**: Use Microsoft Agent Framework with custom `@tool` decorators

**Current Implementation** (`src/azure_agent/neo4j_rag_tools.py`):

```python
class Neo4jRAGTools:
    @tool
    async def query_knowledge_graph(self, query: str, max_results: int = 3):
        # Calls our optimized Neo4jRAG class
        # Preserves 417x performance

    @tool
    async def search_similar_content(self, query: str, threshold: float = 0.7):
        # Vector similarity search

    @tool
    async def get_system_statistics(self):
        # Database and performance stats
```

**Pros**:
- âœ… **Direct integration** - No intermediary MCP server
- âœ… **Full control** - We own the entire stack
- âœ… **Performance** - Direct Aura connection, preserves 417x improvement
- âœ… **Simpler architecture** - Fewer moving parts
- âœ… **Lower cost** - No additional Container App for MCP server
- âœ… **Already implemented** - Code exists, just needs deployment

**Cons**:
- âŒ **Azure AI Foundry only** - Can't use with Claude Desktop, VS Code, etc.
- âŒ **Custom maintenance** - We maintain the tool code
- âŒ **Not standard protocol** - Proprietary to Azure AI Foundry
- âŒ **Current issue**: Functions registered but not deployed/connected

**Architecture**:
```
Azure AI Foundry Assistant â†’ Custom Functions â†’ RAG Service (Container App) â†’ Neo4j Aura
                                                       â†“
                                                  FastAPI endpoints
                                                  Neo4jRAG class (417x optimized)
```

**Estimated Effort**: 1 week
- Days 1-2: Debug current connection issue
- Days 3-4: Deploy RAG service to Container Apps
- Day 5: Connect Azure AI Foundry to service
- Days 6-7: Testing and documentation

---

## ğŸ”§ Current Connection Issue (Option 2 - Debugging)

### Why "I couldn't find this in the knowledge base"?

**Problem Analysis**:

1. **Functions Registered But Not Callable**:
   - Azure AI Foundry shows functions in UI
   - But functions have no endpoint to call
   - Likely pointing to localhost or non-existent service

2. **Missing RAG Service Deployment**:
   - Code exists in `neo4j-rag-demo/src/azure_agent/`
   - But not deployed to Azure Container Apps
   - Functions have no backend to execute

3. **Configuration Gap**:
   - Aura credentials in Key Vault
   - RAG service code exists
   - **Missing**: Container Apps deployment connecting the two

### Solution for Option 2:

**Step 1**: Deploy RAG Service to Container Apps
```bash
# Deploy FastAPI service with Neo4j RAG tools
az containerapp create \
  --name neo4j-rag-service \
  --resource-group rg-neo4j-rag-bitnet \
  --environment neo4j-rag-env \
  --image ghcr.io/ma3u/ms-agentf-neo4j/rag-service:latest \
  --target-port 8000 \
  --env-vars \
    NEO4J_URI=secretref:neo4j-aura-uri \
    NEO4J_PASSWORD=secretref:neo4j-aura-password \
    AZURE_KEY_VAULT_NAME=kv-neo4j-rag-7048
```

**Step 2**: Update Azure AI Foundry Functions
- Point `search_knowledge_base` to: `https://neo4j-rag-service.azurecontainerapps.io/query`
- Point `add_document` to: `https://neo4j-rag-service.azurecontainerapps.io/documents`
- Point `get_statistics` to: `https://neo4j-rag-service.azurecontainerapps.io/stats`

**Step 3**: Test Connection
- Query: "What is Neo4j?"
- Expect: Function calls RAG service â†’ Aura â†’ Returns 5 chunks â†’ GPT-4o-mini generates answer

---

## ğŸ“‹ Detailed Comparison Matrix

| Aspect | Option 1: MCP Servers | Option 2: Agent Framework |
|--------|----------------------|--------------------------|
| **Protocol** | MCP (Standard) | Azure AI Foundry (Proprietary) |
| **Client Support** | Claude, VS Code, Cursor, AI Foundry | Azure AI Foundry only |
| **Neo4j Features** | 4 official servers + custom RAG | Custom RAG tools only |
| **Performance** | Same (both call Aura) | Same (both call Aura) |
| **Cost** | ~$50/mo extra (MCP Container App) | $0 extra (RAG service needed anyway) |
| **Complexity** | Higher (MCP protocol + 5 servers) | Lower (direct tool integration) |
| **Flexibility** | âœ… Multi-client reusable | âŒ Azure-locked |
| **Maintenance** | âœ… Neo4j maintains 4/5 servers | âŒ We maintain everything |
| **Time to Deploy** | 2-3 weeks | 1 week |
| **Current Status** | Not implemented | 80% complete (needs deployment) |
| **Standard Compliance** | âœ… MCP standard | âŒ Proprietary |
| **Learning Curve** | Higher (MCP protocol) | Lower (familiar patterns) |

---

## ğŸ¯ Recommended Approach (Hybrid)

### Phase 1: Fix Option 2 First (1 week)

**Why**: Already 80% complete, fastest path to working system

**Steps**:
1. Deploy RAG service to Container Apps (existing code)
2. Configure Azure AI Foundry functions to call service
3. Test and verify 417x performance maintained
4. Document for NODES 2025 demo

**Result**: Working Azure AI Foundry integration for Nov 6 presentation

---

### Phase 2: Add MCP Servers (Post-NODES, 2-3 weeks)

**Why**: Broader ecosystem support, standard protocol

**Steps**:
1. Deploy 4 neo4j-contrib MCP servers (reuse official code)
2. Build custom MCP server for RAG operations (vector search, hybrid search)
3. Configure Azure AI Foundry to use MCP
4. Enable Claude Desktop, VS Code integration
5. Document multi-client usage

**Result**: Standard MCP integration + multi-client support

---

### Phase 3: Maintain Both (Ongoing)

**Why**: Different use cases need different approaches

**When to use Option 1 (MCP)**:
- Multi-client support needed (Claude Desktop, VS Code)
- Standard protocol compliance required
- Broader ecosystem integration
- Long-term strategic direction

**When to use Option 2 (Agent Framework)**:
- Azure AI Foundry exclusive deployment
- Tightest integration with Azure services
- Simplest architecture
- Lowest cost

---

## ğŸ—ï¸ Proposed Implementation Plan

### Immediate: Fix Option 2 (For NODES 2025)

**Week 1 - Pre-NODES Deployment**:

**Day 1-2**: Deploy RAG Service
```bash
# Build and push image
docker build -t ghcr.io/ma3u/ms-agentf-neo4j/rag-service:v2.0 neo4j-rag-demo
docker push ghcr.io/ma3u/ms-agentf-neo4j/rag-service:v2.0

# Deploy to Container Apps
./scripts/azure-deploy-rag-service.sh
```

**Day 3**: Configure Azure AI Foundry
- Update function URLs to Container App endpoint
- Test `search_knowledge_base` function
- Verify Aura connection

**Day 4**: Test & Validate
- Test queries: "What is Neo4j?", "How does vector search work?"
- Verify 417x performance maintained
- Check cache hit rates

**Day 5**: Document for Demo
- Update Issue #4 with success
- Prepare for live demo November 6

---

### Post-NODES: Add MCP Support (December 2025)

**Week 1**: Deploy Official MCP Servers
```bash
# Clone neo4j-contrib/mcp-neo4j
git clone https://github.com/neo4j-contrib/mcp-neo4j

# Deploy to Container Apps
az containerapp create \
  --name neo4j-mcp-cypher \
  --image ghcr.io/neo4j-contrib/mcp-neo4j-cypher:latest \
  --env-vars NEO4J_URI=secretref:neo4j-aura-uri
```

**Week 2**: Build Custom RAG MCP Server
```typescript
// servers/mcp-neo4j-rag/src/index.ts
import { Server } from "@modelcontextprotocol/sdk/server/index.js";

server.tool("search_knowledge_base", async (query, max_results) => {
  // Call our optimized RAG service
  const response = await fetch(`https://rag-service/query`, {
    method: 'POST',
    body: JSON.stringify({ question: query, k: max_results })
  });
  return response.json();
});
```

**Week 3**: Integration & Testing
- Connect Azure AI Foundry to MCP servers
- Test Claude Desktop integration
- Validate performance
- Documentation

---

## ğŸ“ˆ Neo4j MCP Servers - Which to Use?

### For Our RAG Use Case:

**Use These** âœ…:

1. **mcp-neo4j-cypher** âœ…
   - **Why**: Ad-hoc Cypher queries, schema exploration
   - **Use case**: "Show me all documents", "What's in the database?"
   - **Deploy**: Yes, useful for database management

2. **mcp-neo4j-memory** âœ…
   - **Why**: Conversation history, entity tracking
   - **Use case**: Multi-turn conversations, remember user context
   - **Deploy**: Yes, enhances conversational AI

3. **Custom mcp-neo4j-rag** âœ… (We build this)
   - **Why**: Vector search, hybrid search, RAG operations
   - **Use case**: "What is Neo4j?" â†’ Search 30K chunks â†’ Answer
   - **Deploy**: Yes, core functionality

**Skip These** (For Now) âŒ:

4. **mcp-neo4j-cloud-aura-api** âŒ
   - **Why**: Instance management (create/destroy)
   - **Use case**: DevOps automation
   - **Deploy**: No, we manage Aura manually via console

5. **mcp-neo4j-data-modeling** âŒ
   - **Why**: Schema design for new projects
   - **Use case**: Designing new graph models
   - **Deploy**: No, our schema is stable

### MCP Server Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure AI Foundry Assistant                 â”‚
â”‚  - gpt-4o-mini                              â”‚
â”‚  - MCP client                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ MCP Protocol (HTTP/SSE)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Server Container Apps                  â”‚
â”‚  â”œâ”€ mcp-neo4j-cypher (Queries & Schema)    â”‚
â”‚  â”œâ”€ mcp-neo4j-memory (Conversation Context) â”‚
â”‚  â””â”€ mcp-neo4j-rag (Vector Search) â† Custom â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ Bolt 7687
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Neo4j Aura (6b870b04)                     â”‚
â”‚  - 12 books, 30,006 chunks                  â”‚
â”‚  - Vector + Full-text indexes               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cost**: ~$50/month for MCP Container App (CPU: 1, RAM: 1GB, auto-scale 0-3)

---

## ğŸ”§ Option 2: Current Implementation Debug

### Investigation: Why Functions Don't Work

**File**: `neo4j-rag-demo/src/azure_agent/neo4j_rag_tools.py`

**Code Review**:
```python
class Neo4jRAGTools:
    def __init__(self, neo4j_uri="bolt://localhost:7687", ...):
        self.rag = Neo4jRAG(uri=neo4j_uri, ...)  # âœ… Code exists

    @tool
    async def query_knowledge_graph(self, query: str):
        # âœ… Implementation looks correct
        result = await asyncio.to_thread(self.query_engine.query, query)
        return formatted_response
```

**Issue Identified**:

1. âŒ **RAG Service Not Deployed**
   - Code exists locally
   - Not deployed to Azure Container Apps
   - Azure AI Foundry functions have no endpoint to call

2. âŒ **Function Registration Incomplete**
   - Functions shown in UI (search_knowledge_base, etc.)
   - But no OpenAPI schema provided
   - No service URL configured

3. âŒ **Credentials Not Configured**
   - Functions don't know Aura credentials
   - No environment variables passed
   - Can't connect to `6b870b04` instance

### Fix for Option 2 (Quick Win)

**Solution 1: Deploy as Azure Function** (Serverless):
```bash
# Package as Azure Function
func init neo4j-rag-functions --python
func azure functionapp publish neo4j-rag-func

# Configure in Azure AI Foundry
# Function URL: https://neo4j-rag-func.azurewebsites.net/api/search
```

**Solution 2: Deploy as Container App** (Recommended):
```bash
# Use existing RAG service code
az containerapp create \
  --name neo4j-rag-service \
  --image ghcr.io/ma3u/ms-agentf-neo4j/rag-service:latest \
  --env-vars NEO4J_URI=secretref:neo4j-aura-uri \
  --ingress external --target-port 8000
```

**Solution 3: Use OpenAPI Plugin** (Simplest):
```yaml
# Create OpenAPI spec for Azure AI Foundry
openapi: 3.0.0
info:
  title: Neo4j RAG API
  version: 2.0.0
servers:
  - url: https://neo4j-rag-service.azurecontainerapps.io
paths:
  /query:
    post:
      operationId: search_knowledge_base
      parameters:
        - name: question
        - name: max_results
      responses:
        200:
          description: Search results
```

Upload this to Azure AI Foundry â†’ Functions auto-connect

---

## ğŸ¯ Recommended Decision

### For NODES 2025 (Nov 6 - Immediate)

**âœ… Go with Option 2 (Agent Framework)**

**Why**:
- Fastest to production (1 week vs 2-3 weeks)
- Code already 80% complete
- Simpler for live demo
- Lower cost
- Sufficient for presentation

**Action Plan**:
1. Deploy RAG service today/tomorrow
2. Configure Azure AI Foundry functions
3. Test before November 6
4. Have working demo for talk

---

### For Production (Post-NODES - December)

**âœ… Add Option 1 (MCP Servers)**

**Why**:
- Industry standard protocol
- Multi-client support (Claude Desktop, VS Code)
- Official Neo4j servers (4 ready-made)
- Strategic long-term direction
- Broader ecosystem

**Action Plan**:
1. Keep Option 2 running (it works, don't break it)
2. Add MCP servers in parallel
3. Let users choose (MCP OR Agent Framework)
4. Document both approaches

---

## ğŸ“Š Side-by-Side Comparison

### Feature Comparison

| Feature | Option 1: MCP | Option 2: Agent Framework |
|---------|---------------|--------------------------|
| **Vector Search** | Custom MCP server (we build) | âœ… Built-in (@tool decorator) |
| **Cypher Queries** | âœ… Official mcp-neo4j-cypher | Need to add |
| **Conversation Memory** | âœ… Official mcp-neo4j-memory | Need to add |
| **Aura Management** | âœ… Official mcp-neo4j-cloud-aura-api | Not needed |
| **Multi-client** | âœ… Works everywhere | âŒ Azure only |
| **Performance** | Same 417x | Same 417x |
| **Cost** | ~$250/mo total | ~$200/mo total |
| **Deployment Time** | 2-3 weeks | 1 week |
| **Maintenance** | Neo4j + custom | All custom |
| **Standards** | âœ… MCP protocol | âŒ Proprietary |

### Performance Comparison

Both achieve **417x improvement** because both call the same optimized Neo4jRAG class:

```python
# Both use this under the hood:
class Neo4jRAG:
    def __init__(self):
        self._connection_pool = Pool(max_size=10)  # 10x improvement
        self._query_cache = FIFOCache(maxsize=100)  # 100x on hits
        self._enable_parallel_search = True         # 2x improvement
        # ... other optimizations
```

**Conclusion**: Performance is identical, architecture differs

---

## ğŸš€ Implementation Roadmap

### Phase 1: Option 2 (Now - Before NODES)

**Timeline**: October 18-25, 2025 (1 week)

**Milestones**:
- [ ] Day 1: Deploy RAG service to Container Apps
- [ ] Day 2: Configure Azure AI Foundry functions with service URL
- [ ] Day 3: Test queries ("What is Neo4j?", "How does RAG work?")
- [ ] Day 4: Performance validation (417x maintained?)
- [ ] Day 5: Documentation update
- [ ] Day 6-7: Buffer for issues

**Success Criteria**:
- âœ… Assistant answers "What is Neo4j?" correctly
- âœ… Cites sources from 12 books
- âœ… Response time <500ms
- âœ… Ready for NODES demo

---

### Phase 2: Add MCP Support (December 2025)

**Timeline**: December 2-20, 2025 (3 weeks)

**Milestones**:
- [ ] Week 1: Deploy neo4j-contrib MCP servers (cypher, memory)
- [ ] Week 2: Build custom mcp-neo4j-rag server
- [ ] Week 3: Integration testing, multi-client validation

**Success Criteria**:
- âœ… Works in Claude Desktop
- âœ… Works in VS Code with Copilot
- âœ… Works in Azure AI Foundry (via MCP)
- âœ… Same 417x performance

---

## ğŸ“ Next Steps

### Immediate Actions (This Week):

1. **Create Deployment Script**:
   - `scripts/azure-deploy-rag-service.sh`
   - Deploys Container App with Aura credentials
   - Configures endpoints

2. **Update Azure AI Foundry**:
   - Add service URL to functions
   - Test connection
   - Validate responses

3. **Document Success**:
   - Update Issue #4 with results
   - Add to NODES presentation if time permits

### Post-NODES Actions (December):

1. **MCP Server Development**:
   - Fork neo4j-contrib/mcp-neo4j
   - Add custom RAG server
   - Deploy to Azure

2. **Multi-Client Testing**:
   - Claude Desktop setup
   - VS Code Copilot integration
   - Documentation for users

3. **Comparison Documentation**:
   - When to use MCP vs Agent Framework
   - Performance benchmarks
   - Cost analysis

---

## ğŸ’¡ Key Insights

### Why Option 2 Currently Fails

**Root Cause**: Functions exist in code, registered in Azure AI Foundry UI, but have **no backend service** to execute them.

**Analogy**: It's like having a phone number in your contacts, but nobody's answering because the server isn't deployed.

**Fix**: Deploy the RAG service â†’ Functions can call it â†’ Everything works

### Why Both Options Make Sense

**Option 2 (Agent Framework)**:
- Best for: Azure-centric deployments
- Advantage: Simplicity, direct integration
- Trade-off: Azure vendor lock-in

**Option 1 (MCP)**:
- Best for: Multi-client, standard protocol
- Advantage: Broader ecosystem, official support
- Trade-off: More complex, higher cost

**Conclusion**: Deploy Option 2 now, add Option 1 later. Both can coexist.

---

## ğŸ“Š Cost Comparison

### Option 2 Only (Current Plan):
- Neo4j Aura: $65-200/month
- RAG Service Container App: $50-150/month
- Azure AI Foundry API calls: ~$20-50/month
- **Total**: ~$135-400/month

### Option 1 + Option 2 (Post-NODES):
- Neo4j Aura: $65-200/month
- RAG Service: $50-150/month
- MCP Server: $25-75/month (smaller instance)
- Azure AI Foundry: ~$20-50/month
- **Total**: ~$160-475/month

**Difference**: +$25-75/month for MCP support

**Value**: Multi-client support, standard protocol, broader ecosystem

---

## âœ… Recommendation Summary

**For NODES 2025 Presentation (Nov 6)**:
- âœ… Fix Option 2 (Agent Framework)
- âœ… Deploy RAG service this week
- âœ… Have working demo
- âœ… Mention MCP as "future direction"

**For Production (Post-NODES)**:
- âœ… Keep Option 2 (it works, users like it)
- âœ… Add Option 1 (MCP) for broader support
- âœ… Let users choose based on needs
- âœ… Document both approaches

**Best Practice**:
- Start simple (Option 2)
- Add complexity when needed (Option 1)
- Support both long-term (different use cases)

---

**Next Steps**:
1. Create `azure-deploy-rag-service.sh` script
2. Deploy to Container Apps
3. Test Azure AI Foundry connection
4. Update Issue #4 with results

**Estimated Time**: 4-8 hours of focused work

---

**Author**: Investigation by Claude Code
**For**: NODES 2025 preparation
**GitHub Issue**: #4
**Target**: Working demo by November 6, 2025
