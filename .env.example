# BitNet b1.58 Ultra-Efficient RAG Configuration
# Copy this to .env and fill in your values

# Neo4j Configuration
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Azure OpenAI Configuration (for cost-effective embeddings)
# Get these from Azure Portal > Azure OpenAI Service
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_API_KEY=your-azure-openai-key

# BitNet b1.58 Configuration (optional - uses fallback if not configured)
# Deploy BitNet in Azure AI Foundry Model Catalog
BITNET_ENDPOINT=https://your-bitnet.azureml.azure.com/
BITNET_API_KEY=your-bitnet-api-key

# Application Settings
BITNET_MODE=enabled
LOG_LEVEL=INFO

# Performance Tuning
MAX_WORKERS=1          # Single worker for ultra-efficiency
CACHE_SIZE=50          # Minimal cache
MEMORY_LIMIT_GB=0.5    # BitNet's ultra-low footprint

# ====================================
# BitNet Efficiency Metrics:
# ====================================
# Container Size: ~500MB (vs 5GB+ traditional)
# Memory Usage: 0.4-0.5GB (vs 2-4.8GB traditional)  
# Inference Latency: ~29ms (vs 41-124ms traditional)
# Energy per Query: 0.028J (vs 0.186-0.649J traditional)
# Monthly Cost: $15-30 (vs $200-500+ traditional)
#
# Savings: 87% memory, 77% faster, 96% energy, 85-90% cost reduction
